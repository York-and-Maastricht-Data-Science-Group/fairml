[% import 'fairml.eol'; %]
[% fairml.initialise(); %]
[%var tempTrainingMethods = 0; %]
[%var number1 = 0; %]
[%var number2 = 0; %]
[%var number3 = 0; %]
[%var number4 = 0; %]
[%var number5 = 0; %]
# # FairML: [%=fairml.name%]
# [%=fairml.description.replace("\n","\\\n# ")%]

# # Contents
# [FairML: [%=fairml.name%]](#FairML:-[%=fairml.name.replace(" ", "-")%])
# [Contents](#Contents)
[% for (biasMitigation in fairml.biasMitigations) { %]
# * [[%=number1++%]. Bias Mitigation: [%=biasMitigation.name%]](#[%=number1%].-Bias-Mitigation:-[%=biasMitigation.name.replace(" ", "-")%])
[%number2 = 0; number3 = 0; number4 = 0; number5 = 0; %]
  [% for (dataset in biasMitigation.datasets) { %]
#   * [[%=number1%].[%=number2++%]. Dataset [%=dataset.name%]](#[%=number1%].[%=number2%].-Dataset-[%=dataset.name.replace(" ", "-")%])
        [%number3 = 0; number4 = 0; number5 = 0; %]
#       * [[%=number1%].[%=number2%].[%=number3++%]. Original Dataset](#[%=number1%].[%=number2%].[%=number3%].-Original-Dataset)
    [% for (trainingMethod in biasMitigation.trainingMethods) { %]
     [%number5 = 0;%]
#           * [[%=number1%].[%=number2%].[%=number3%].[%=number4++%]. Classifier [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]](#[%=number1%].[%=number2%].[%=number3%].[%=number4%].-Original-Dataset:-Classifier-[%=trainingMethod.algorithm%],-Parameters:-[%=trainingMethod.parameters.listToLineWithoutQuote().replace(" ", "-")%])
#               * [[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5++%]. Bias Metrics](#[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5%].-Original-Dataset:-Bias-Metrics)
    [% } %]
    [% for (mitigationMethod in biasMitigation.mitigationMethods) { %]
#       * [[%=number1%].[%=number2%].[%=number3++%]. Mitigate Bias using [%=mitigationMethod.algorithm%]](#[%=number1%].[%=number2%].[%=number3%].-Mitigate-Bias-using-[%=mitigationMethod.algorithm%])
      [% number4 = 0; number5 = 0; %]
        [% if (inprocessings.exists(p | p = mitigationMethod.algorithm)) {
           // move existing training methods to a temperary variable
           // so that the IN-PROCESSING MITIGATION can take place   
           tempTrainingMethods = biasMitigation.trainingMethods.clone();
           biasMitigation.trainingMethods.clear();
           var tm = new TrainingMethod();
           tm.algorithm = mitigationMethod.algorithm;
           tm.parameters = mitigationMethod.parameters.clone();
           tm.fitParameters = mitigationMethod.fitParameters.clone();
           tm.predictParameters = mitigationMethod.predictParameters.clone();
           biasMitigation.trainingMethods.add(tm);
        } %]
      [% for (trainingMethod in biasMitigation.trainingMethods) { %]
        [%number5 = 0;%]
#           * [[%=number1%].[%=number2%].[%=number3%].[%=number4++%]. Classifier [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]](#[%=number1%].[%=number2%].[%=number3%].[%=number4%].-After-mitigation-Dataset:-Classifier-[%=trainingMethod.algorithm%],-Parameters:-[%=trainingMethod.parameters.listToLineWithoutQuote().replace(" ", "-")%])
#               * [[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5++%]. Bias Metrics](#[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5%].-After-mitigation:-Bias-Metrics)
      [% } %]
        [% if (inprocessings.exists(p | p = mitigationMethod.algorithm)) { 
           // move BACK existing training methods in the temporary variable to bias mitigation 
           biasMitigation.trainingMethods.clear();
           biasMitigation.trainingMethods.addAll(tempTrainingMethods);
           tempTrainingMethods = biasMitigation.trainingMethods.clone();
        } %]
    [% } %]
  [% } %]
#   * [[%=number1%].[%=number2++%]. Summary](#[%=number1%].[%=number2%].-Summary)
[% } %]
[%number1 = 0; %]
[%number2 = 0; %]
[%number3 = 0; %]
[%number4 = 0; %]
[%number5 = 0; %]

# Load dependencies.

import inspect
import numpy as np
np.random.seed(0)
import pandas as pd
import matplotlib
from fairml import *
from sklearn import tree
from sklearn.tree import *
from sklearn.linear_model import *
from sklearn.svm import *
from sklearn.neighbors import *
from sklearn.naive_bayes import *
from sklearn.neural_network import *
from sklearn.kernel_ridge import *
from sklearn.ensemble import *
from sklearn import metrics
from sklearn.preprocessing import MaxAbsScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from aif360.algorithms.preprocessing import *
from aif360.algorithms.inprocessing import *
from aif360.algorithms.postprocessing import *
from aif360.datasets import StandardDataset
from collections import defaultdict
from IPython.display import Markdown, display
from IPython import get_ipython
[% for (module in fairml.modules) { %]
[%=module%]
[% } %]

fairml = FairML()
def get_fairml():
    return fairml

print("========================")
print("FairML: [%=fairml.name%]")
print("========================")
print("Description:")
print("[%=fairml.description.replace("\n","\"+\\\n\"")%]")

[% for (biasMitigation in fairml.biasMitigations) { %]
[%number2 = 0; number3 = 0; number4 = 0; number5 = 0; %]
# ## [[%=number1++%].](#Contents) Bias Mitigation: [%=biasMitigation.name%]
bm = fairml.add_bias_mitigation(BiasMitigation())
bm.name = "[%=biasMitigation.name%]"

print("")
print("========================")
print("Bias Mitigation: [%=biasMitigation.name%]")
print("------------------------")

[% for (dataset in biasMitigation.datasets) { %]
[%number3 = 0; number4 = 0; number5 = 0; %]
# ### [[%=number1%].[%=number2++%].](#Contents) Dataset [%=dataset.name%]
print("")
print("Dataset: [%=dataset.name%]")
print("-------------")

# #### [[%=number1%].[%=number2%].[%=number3++%].](#Contents) Original Dataset
bm.predicted_attribute = '[%=dataset.predictedAttribute%]'
bm.protected_attributes = [[%=dataset.protectedAttributes.listToLine()%]]
bm.features_to_keep = [[%=dataset.featuresToKeep.listToLine()%]]
bm.favorable_class = 1
bm.privileged_class = 1
bm.unprivileged_class = 0
bm.dropped_attributes = []
bm.na_values = []
[%
if (dataset.trainTestValidationSplit == null or 
    dataset.trainTestValidationSplit.size() == 0) {
    dataset.trainTestValidationSplit = Sequence{8.0, 2.0, 0.0};    
} else if (dataset.trainTestValidationSplit.size() == 1) {
    dataset.trainTestValidationSplit = Sequence{
    dataset.trainTestValidationSplit[0].abs(), 
    0.0, 0.0};    
} else if (dataset.trainTestValidationSplit.size() == 2) {
    dataset.trainTestValidationSplit = Sequence{
    dataset.trainTestValidationSplit[0].abs(), 
    dataset.trainTestValidationSplit[1].abs(), 0.0};    
} else if (dataset.trainTestValidationSplit.size() >= 3) {
    dataset.trainTestValidationSplit = Sequence{
    dataset.trainTestValidationSplit[0].abs(), 
    dataset.trainTestValidationSplit[1].abs(), 
    dataset.trainTestValidationSplit[2].abs() 
    };    
} %]
bm.training_size = [%=dataset.trainTestValidationSplit[0]%]    
bm.test_size = [%=dataset.trainTestValidationSplit[1]%]
bm.validation_size = [%=dataset.trainTestValidationSplit[2]%]
bm.total_size = bm.training_size + bm.test_size + bm.validation_size
bm.categorical_features = [[%=dataset.categoricalFeatures.listToLine()%]]
[% if (dataset.defaultMappings == null) {%]
bm.default_mappings = None
[% } %]

# Load dataset
bm.resource = "[%=dataset.datasetPath%]" 
[% if (dataset.datasetPath != null and dataset.datasetPath.length() > 0) { %]
bm.data = pd.read_csv(bm.resource, header=0)
bm.dataset_original = StandardDataset(df=bm.data, label_name=bm.predicted_attribute,
                favorable_classes=[bm.favorable_class],
                protected_attribute_names=bm.protected_attributes,
                privileged_classes=[[bm.privileged_class]],
                instance_weights_name=None,
                categorical_features=bm.categorical_features,
                features_to_keep=bm.features_to_keep,
                features_to_drop=bm.dropped_attributes,
                na_values=bm.na_values,
                custom_preprocessing=None,
                metadata=bm.default_mappings)
[% } else if (dataset.datasetModule != null and dataset.datasetModule.length() > 0) { %]
bm.dataset_original = [%=dataset.datasetModule%]([%=dataset.datasetModuleParameters.listToLineWithoutQuote()%])
[% } %]

[% if ((dataset.datasetPath != null and dataset.datasetPath.length() > 0)
        or (dataset.datasetModule != null and dataset.datasetModule.length() > 0)) { %]
[%   if (dataset.trainTestValidationSplit[2] == 0 and dataset.trainTestValidationSplit[1] <> 0) { %]
bm.dataset_original_train, bm.dataset_original_test = bm.dataset_original.split([bm.training_size/bm.total_size], shuffle=True)
[%   } else if (dataset.trainTestValidationSplit[2] == 0 and dataset.trainTestValidationSplit[1] == 0) { %]
bm.dataset_original_train, bm.dataset_original_test = bm.dataset_original.split([int(bm.training_size)])
if bm.dataset_original_train.features.shape[0] < bm.dataset_original_test.features.shape[0]:
   bm.dataset_original_test, bm.dataset_original_train = bm.dataset_original_train, bm.dataset_original_test
 
if bm.dataset_original_test.features.shape[0] == 0:
    bm.dataset_original_test = bm.dataset_original_train.copy(deepcopy=True)     
 
bm.training_size = bm.dataset_original_train.features.shape[0]    
bm.test_size = bm.dataset_original_test.features.shape[0]
bm.validation_size = 0
bm.total_size = bm.training_size + bm.test_size + bm.validation_size
[%   } else { %]
bm.dataset_original_train, bm.dataset_original_valid, bm.dataset_original_test = bm.dataset_original.split([bm.training_size/bm.total_size, (bm.training_size + bm.validation_size)/bm.total_size], shuffle=True)
[%   } %]
[% } %]

[% if (dataset.trainDatasetModule != null and dataset.trainDatasetModule.length() > 0) { %]
bm.train_dataset_module = [%=dataset.trainDatasetModule%]()
[%   if (dataset.trainTestValidationSplit[2] == 0) { %]
bm.dataset_original_train, _ = bm.train_dataset_module.split([bm.training_size/bm.total_size], shuffle=True)
[%   } else { %]
bm.dataset_original_train, _ , _ = bm.train_dataset_module.split([bm.training_size/bm.total_size, (bm.training_size + bm.validation_size)/bm.total_size], shuffle=True)
[%   } %]
[% } %]

[% if (dataset.testDatasetModule != null and dataset.testDatasetModule.length() > 0) { %]
bm.test_dataset_module = [%=dataset.testDatasetModule%]()
bm.test_dataset_module = bm.dataset_original_train.align_datasets(bm.test_dataset_module)
[%   if (dataset.trainTestValidationSplit[2] == 0) { %]
_ , bm.dataset_original_test = bm.test_dataset_module.split([bm.training_size/bm.total_size], shuffle=True)
[%   } else { %]
_ , _ , bm.dataset_original_test = bm.test_dataset_module.split([bm.training_size/bm.total_size, (bm.training_size + bm.validation_size)/bm.total_size], shuffle=True)
[%   } %]
[% } %]

[% if (dataset.validationDatasetModule != null and dataset.validationDatasetModule.length() > 0) { %]
bm.validation_dataset_module = [%=dataset.validationDatasetModule%]()
bm.dataset_original_valid = bm.validation_dataset_module.align_datasets(bm.dataset_original_validation)
_ , bm.dataset_original_valid, _ = bm.validation_dataset_module.split([bm.training_size/bm.total_size, (bm.training_size + bm.validation_size)/bm.total_size], shuffle=True)
[% } %]

bm.privileged_groups = [{bm.protected_attributes[0] : bm.privileged_class}]
bm.unprivileged_groups = [{bm.protected_attributes[0] : bm.unprivileged_class}]

[% if (biasMitigation.trainingMethods.size() == 0) { %]
bm.init_new_result("Original", "", "[%=dataset.name%]", "", "")
[%    for (biasMetric in biasMitigation.biasMetrics) { %]
[%      if (biasMetric.datasetType == "train") { %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_train, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups, [%=biasMetric.parameters.listToLineWithoutQuote()%])
[%      } else if (biasMetric.datasetType == "test") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_test, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%      } else if (biasMetric.datasetType == "validation") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_valid, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[% } %]
[%    } %]
[%  } %]

[%    for (trainingMethod in biasMitigation.trainingMethods) { %]

# ##### [[%=number1%].[%=number2%].[%=number3%].[%=number4++%].](#Contents) Original Dataset: Classifier [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]
[%number5 = 0;%]
print("")
print("Original Dataset: Classifier [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]")
print("-------------")

# Train the model from the original train data
classifier = [%=trainingMethod.algorithm%]([%=trainingMethod.parameters.listToLineWithoutQuote()%])
model_original_train = bm.train(bm.dataset_original_train,  classifier)

# ###### [[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5++%].](#Contents) Original Dataset: Bias Metrics[% // start of metrics %]

print("Original Bias Metrics")
dataset_original_train_pred = bm.create_predicted_dataset(bm.dataset_original_train, model_original_train)
dataset_original_test_pred = bm.create_predicted_dataset(bm.dataset_original_test, model_original_train)

bm.init_new_result("Original", "", "[%=dataset.name%]", "[%=trainingMethod.algorithm%]", "[%=trainingMethod.parameters.listToLineWithoutQuote()%]")

[%    for (biasMetric in biasMitigation.biasMetrics) { %]
[%      if (biasMetric.className == "FairMLMetric") { %]
[%          if (biasMetric.datasetType == "train") { %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_train, predicted_dataset=dataset_original_train_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%          } else if (biasMetric.datasetType == "test") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_test, predicted_dataset=dataset_original_test_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%          } else if (biasMetric.datasetType == "validation") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=bm.dataset_original_valid, predicted_dataset=dataset_original_valid_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%          } %]
[%      } %]
[%    } %][% // end of original metrics %]
[%  } %][% // end of original training %]

    [% for (mitigationMethod in biasMitigation.mitigationMethods) { %]

# #### [[%=number1%].[%=number2%].[%=number3++%].](#Contents) Mitigate Bias using [%=mitigationMethod.algorithm%]  
[% number4 = 0; number5 = 0; %]
print("")
print("Mitigate Bias using [%=mitigationMethod.algorithm%]")
print("-------------")
[% if (preprocessings.exists(p | p = mitigationMethod.algorithm)) { %]
[%   if (mitigationMethod.algorithm <> "DisparateImpactRemover" ) { %]
mitigation_method = bm.create_mitigation_method([%=mitigationMethod.algorithm%], [%=mitigationMethod.parameters.listToLineWithoutQuote()%])
dataset_mitigated_train = mitigation_method.fit_transform(bm.dataset_original_train)
[%   if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid = mitigation_method.fit_transform(bm.dataset_original_valid)
[%   } %]
dataset_mitigated_test = mitigation_method.fit_transform(bm.dataset_original_test)
[% } else { %]

scaler = MinMaxScaler(copy=False)
temp_train = bm.dataset_original_train.copy(deepcopy=True)
temp_test = bm.dataset_original_test.copy(deepcopy=True)
temp_train.features = scaler.fit_transform(temp_train.features)
temp_test.features = scaler.fit_transform(temp_test.features)
[%   if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
temp_valid = bm.dataset_original_valid.copy(deepcopy=True)
temp_valid.features = scaler.fit_transform(temp_valid.features)
[%   } %]

mitigation_method = bm.create_mitigation_method([%=mitigationMethod.algorithm%], [%=mitigationMethod.parameters.listToLineWithoutQuote()%])
dataset_mitigated_train = mitigation_method.fit_transform(temp_train)
dataset_mitigated_test = mitigation_method.fit_transform(temp_test)
[%   if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid = mitigation_method.fit_transform(temp_valid)
[%   } %]

index = bm.dataset_original_train.feature_names.index(bm.protected_attributes[0])
dataset_mitigated_train.features = np.delete(dataset_mitigated_train.features, index, axis=1)
dataset_mitigated_test.features = np.delete(dataset_mitigated_test.features, index, axis=1)
[%   } %]
[% } else if (inprocessings.exists(p | p = mitigationMethod.algorithm)) {
   // move existing training methods to a temperary variable
   // so that the IN-PROCESSING MITIGATION can take place   
   tempTrainingMethods = biasMitigation.trainingMethods.clone();
   biasMitigation.trainingMethods.clear();
   var tm = new TrainingMethod();
   tm.algorithm = mitigationMethod.algorithm;
   tm.parameters = mitigationMethod.parameters.clone();
   biasMitigation.trainingMethods.add(tm); %]
dataset_mitigated_train = bm.dataset_original_train.copy(deepcopy=True)
[% if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid = bm.dataset_original_valid.copy(deepcopy=True)
[% } %]
dataset_mitigated_test = bm.dataset_original_test.copy(deepcopy=True)
min_max_scaler = MaxAbsScaler()
dataset_mitigated_train.features = min_max_scaler.fit_transform(bm.dataset_original_train.features)
[% if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid.features = min_max_scaler.fit_transform(bm.dataset_original_valid.features)
[% } %]
dataset_mitigated_test.features = min_max_scaler.fit_transform(bm.dataset_original_test.features)
[% } else if (postprocessings.exists(p | p = mitigationMethod.algorithm)) { %]
mitigation_method = bm.create_mitigation_method([%=mitigationMethod.algorithm%], [%=mitigationMethod.parameters.listToLineWithoutQuote()%])
dataset_mitigated_train = bm.dataset_original_train.copy(deepcopy=True)
[% if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid = bm.dataset_original_valid.copy(deepcopy=True)
[% } %]
dataset_mitigated_test = bm.dataset_original_test.copy(deepcopy=True)
standard_scaler = StandardScaler()
dataset_mitigated_train.features = standard_scaler.fit_transform(bm.dataset_original_train.features)
[% if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid.features = standard_scaler.fit_transform(bm.dataset_original_valid.features)
[% } %]
dataset_mitigated_test.features = standard_scaler.fit_transform(bm.dataset_original_test.features)
[% } %]

[% if(biasMitigation.trainingMethods.size() == 0) { %]
bm.init_new_result("[%=mitigationMethod.algorithm%]", "[%=mitigationMethod.parameters.listToLineWithoutQuote()%]", "[%=dataset.name%]", "", "")
[%   for (biasMetric in biasMitigation.biasMetrics) { %]
[%      if (biasMetric.datasetType == "train") { %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_train, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%      } else if (biasMetric.datasetType == "test") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_test, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%      } else if (biasMetric.datasetType == "validation") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_valid, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups)
[%      } %]
[%   } %]
[% } %]

[%      for (trainingMethod in biasMitigation.trainingMethods) { %]

# ##### [[%=number1%].[%=number2%].[%=number3%].[%=number4++%].](#Contents) After-mitigation Dataset: Classifier [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]
[% number5=0; %]
print("")
print("After-mitigation Training: [%=trainingMethod.algorithm%], Parameters: [%=trainingMethod.parameters.listToLineWithoutQuote()%]")
print("-------------")

# Train the model from the after-mitigation train data

[% if (inprocessings.exists(p | p = mitigationMethod.algorithm)) { %]
classifier = bm.create_mitigation_method([%=mitigationMethod.algorithm%], [%=mitigationMethod.parameters.listToLineWithoutQuote()%])
model_mitigated_train = classifier.fit(dataset_mitigated_train, [%=mitigationMethod.fitParameters.listToLineWithoutQuote()%])
[% } else { %]
classifier = [%=trainingMethod.algorithm%]([%=trainingMethod.parameters.listToLineWithoutQuote()%])
model_mitigated_train = bm.train(dataset_mitigated_train,  classifier)
[% } %]

# ###### [[%=number1%].[%=number2%].[%=number3%].[%=number4%].[%=number5++%].](#Contents) After-mitigation: Bias Metrics

print("After-mitigation Metrics")
[% if (inprocessings.exists(p | p = mitigationMethod.algorithm)) { %]
dataset_mitigated_train_pred = model_mitigated_train.predict(dataset_mitigated_train, [%=mitigationMethod.predictParameters.listToLineWithoutQuote()%])
[%   if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid_pred = model_mitigated_train.predict(dataset_mitigated_valid, [%=mitigationMethod.predictParameters.listToLineWithoutQuote()%])
[%    } %]
dataset_mitigated_test_pred = model_mitigated_train.predict(dataset_mitigated_test, [%=mitigationMethod.predictParameters.listToLineWithoutQuote()%])
[% } else { %]
dataset_mitigated_train_pred = bm.create_predicted_dataset(dataset_mitigated_train, model_mitigated_train)
[%   if (dataset.trainTestValidationSplit.size() > 2 and dataset.trainTestValidationSplit[2] > 0) { %]
dataset_mitigated_valid_pred = bm.create_predicted_dataset(dataset_mitigated_valid, model_mitigated_train)
[%   } %]
dataset_mitigated_test_pred = bm.create_predicted_dataset(dataset_mitigated_test, model_mitigated_train)
[% } %]

[% if (postprocessings.exists(p | p = mitigationMethod.algorithm)) { %]
dataset_mitigated_test_pred.labels = dataset_mitigated_test_pred.labels.reshape((-1, 1))
[%  if (mitigationMethod.algorithm == "CalibratedEqOddsPostprocessing") { %]
y_test_pred_prob = bm.get_prediction_probability(model_mitigated_train, bm.dataset_original_train, dataset_mitigated_test.features)
y_test_pred = np.zeros_like(dataset_mitigated_test_pred.labels)
class_thresh = 0.5
y_test_pred[y_test_pred_prob >= class_thresh] = dataset_mitigated_test_pred.favorable_label
y_test_pred[~(y_test_pred_prob >= class_thresh)] = dataset_mitigated_test_pred.unfavorable_label
dataset_mitigated_test_pred.labels = y_test_pred    
[%  } %]
mitigation_method = mitigation_method.fit(dataset_mitigated_valid, dataset_mitigated_valid_pred)
dataset_mitigated_test_pred = mitigation_method.predict(dataset_mitigated_test_pred)
[% } %]

bm.init_new_result("[%=mitigationMethod.algorithm%]", "[%=mitigationMethod.parameters.listToLineWithoutQuote()%]", "[%=dataset.name%]", "[%=trainingMethod.algorithm%]", "[%=trainingMethod.parameters.listToLineWithoutQuote()%]")

[%      for (biasMetric in biasMitigation.biasMetrics) { %]
[%        if (biasMetric.className == "FairMLMetric" ) { %]
[%          if (biasMetric.datasetType == "train") { %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_train, predicted_dataset=dataset_mitigated_train_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups, [%=biasMetric.parameters.listToLineWithoutQuote()%])
[%          } else if (biasMetric.datasetType == "test") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_test, predicted_dataset=dataset_mitigated_test_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups, [%=biasMetric.parameters.listToLineWithoutQuote()%])
[%          } else if (biasMetric.datasetType == "validation") {  %]
bm.measure_bias("[%=biasMetric.name%]", baseline_dataset=dataset_mitigated_valid, predicted_dataset=dataset_mitigated_valid_pred, privileged_groups=bm.privileged_groups, unprivileged_groups=bm.unprivileged_groups, [%=biasMetric.parameters.listToLineWithoutQuote()%])
[%          } %]
[%        } else { %]
[%        } %]
[%      } %]
[%     } %]
[%    if (inprocessings.exists(p | p = mitigationMethod.algorithm)) { 
       // move BACK existing training methods in the temporary variable to bias mitigation 
       biasMitigation.trainingMethods.clear();
       biasMitigation.trainingMethods.addAll(tempTrainingMethods);
       tempTrainingMethods = biasMitigation.trainingMethods.clone();
} %]
[%  } %]

[%  } %]

# ### [[%=number1%].[%=number2++%].](#Contents) Summary

table = bm.display_summary()
table.style.set_caption("Worst = White, Best = Green, Mid = Yellow") \
    .apply(bm.highlight_fairest_values, axis=1)

if get_ipython() is not None:
    get_ipython().magic("matplotlib inline")
bm.display_barchart()

[% } %]
[% //fairml.p2j(); %]
